{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HWE6l2IqouF-"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST Database\n",
        "The database contains 60,000 training images and 10,000 testing images.\n",
        "\n",
        "Each image is a 28x28 pixel grayscale image of a single digit between 0 and 9.\n",
        "\n"
      ],
      "metadata": {
        "id": "AI8qmTddpGu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loads the MNIST data using fetch_openml\n",
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
      ],
      "metadata": {
        "id": "NQ2CdofEpAtI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splits the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, test_size=10000)"
      ],
      "metadata": {
        "id": "ocnJrS41pk7L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimensions of your training and testing datasets\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(\"The first image in X_train is a handwritten digit representing the number\",y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvcEHWXRpoIV",
        "outputId": "56ff2cce-817b-4946-8cbe-24d9cc53140f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000,)\n",
            "The first image in X_train is a handwritten digit representing the number 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(X_train[0].reshape(28,28), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "meexeegkqt-S",
        "outputId": "a8bc3ee3-aa60-499e-e69d-c7467a414b28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax regression\n",
        "\n",
        "Softmax regression is designed for multiclass classification problems where each instance belongs to one of multiple classes. In the MNIST dataset, each image belongs to one of 10 digit classes (0 through 9).\n",
        "\n",
        "The softmax function converts raw prediction scores (logits) into probabilities that sum to 1 across all classes. This probabilistic interpretation is useful for understanding model confidence and making decisions based on predicted probabilities.\n",
        "\n",
        "Softmax regression extends the concept of logistic regression (binary classification) to multiple classes. It models the relationship between input features (pixel values) and the probability of each class using a linear combination of features, making it simple and interpretable.\n",
        "\n",
        "While MNIST data may not be perfectly linearly separable, softmax regression can still provide a strong baseline for performance and is often used as a comparison point for more complex models like neural networks.\n"
      ],
      "metadata": {
        "id": "cYYEI2wNq7BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(multi_class='multinomial',solver='lbfgs',max_iter=1000, C=1e10)"
      ],
      "metadata": {
        "id": "34-4GnkErpty"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "bfuhWGYzru4i",
        "outputId": "2fb3a84c-7f4c-44b4-851f-0787c45dcf2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000000000.0, max_iter=1000, multi_class='multinomial')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000000000.0, max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10000000000.0, max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.coef_.shape)\n",
        "print(clf.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Zq1_PyrxE5",
        "outputId": "a087333b-f206-4aa4-f931-a398bf4b9e02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 784)\n",
            "[-0.0042279   0.00529454  0.00478578 -0.00866698  0.00257962  0.0318295\n",
            " -0.00135109  0.00972853 -0.03251359 -0.00745842]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlLLyTAfrz3A",
        "outputId": "9bf88caa-0b28-4dc3-f954-a9e28493e5ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9145"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax regression with Stochastic Gradient Descent from scratch\n",
        "1.   Load and Preprocess the Data\n",
        "2.   Initialize Parameters\n",
        "3.   Define the Softmax Function\n",
        "4.   Compute the Loss Function\n",
        "5.   Implement Stochastic Gradient Descent\n",
        "6.   Train the Model\n",
        "7.   Evaluate the Model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uO3dYPQpsObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "ApRDCvs9snNk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "y = one_hot_encoder.fit_transform(y.reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA8dtB_cs5FD",
        "outputId": "db414ad8-cab7-4ba0-ce8f-220856fbc00f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, test_size=10000, random_state=42)"
      ],
      "metadata": {
        "id": "UGtEhtV6tusZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "E-cZayPjtxEd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and biases\n",
        "def initialize_parameters(n_features, n_classes):\n",
        "    W = np.random.randn(n_features, n_classes) * 0.01\n",
        "    b = np.zeros((1, n_classes))\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "GtkmOmOOt3Pz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the Softmax Function\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Prevent overflow\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "5xVaHgjYt7Og"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the Loss Function\n",
        "def compute_loss(y_true, y_pred):\n",
        "    m = y_true.shape[0]\n",
        "    loss = -np.sum(y_true * np.log(y_pred + 1e-8)) / m  # Add epsilon to avoid log(0)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Pc3tDUGpt-Vc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement Stochastic Gradient Descent\n",
        "def sgd_step(X, y, W, b, learning_rate):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # Forward pass\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "\n",
        "    # Compute gradients\n",
        "    dz = y_pred - y\n",
        "    dW = np.dot(X.T, dz) / m\n",
        "    db = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "    # Update parameters\n",
        "    W -= learning_rate * dW\n",
        "    b -= learning_rate * db\n",
        "\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "hFHC5OopuGKQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "def train(X_train, y_train, n_classes, learning_rate=0.01, epochs=100, batch_size=32):\n",
        "    n_features = X_train.shape[1]\n",
        "    W, b = initialize_parameters(n_features, n_classes)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        permutation = np.random.permutation(X_train.shape[0])\n",
        "        X_train_shuffled = X_train[permutation]\n",
        "        y_train_shuffled = y_train[permutation]\n",
        "\n",
        "        for i in range(0, X_train.shape[0], batch_size):\n",
        "            X_batch = X_train_shuffled[i:i+batch_size]\n",
        "            y_batch = y_train_shuffled[i:i+batch_size]\n",
        "            W, b = sgd_step(X_batch, y_batch, W, b, learning_rate)\n",
        "\n",
        "        # Compute loss after each epoch\n",
        "        z = np.dot(X_train, W) + b\n",
        "        y_train_pred = softmax(z)\n",
        "        loss = compute_loss(y_train, y_train_pred)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss}')\n",
        "\n",
        "    return W, b"
      ],
      "metadata": {
        "id": "S8RLdBS0uNcp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Model\n",
        "def predict(X, W, b):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "    return np.argmax(y_pred, axis=1)\n",
        "\n",
        "def evaluate(X, y, W, b):\n",
        "    y_pred = predict(X, W, b)\n",
        "    y_true = np.argmax(y, axis=1)\n",
        "    accuracy = np.mean(y_pred == y_true) * 100\n",
        "    return accuracy\n",
        "\n",
        "# Train the model\n",
        "n_classes = y_train.shape[1]\n",
        "W, b = train(X_train, y_train, n_classes, learning_rate=0.01, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = evaluate(X_test, y_test, W, b)\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KNaW85cuTRE",
        "outputId": "98a4d258-2a0c-4f9a-fbcb-a6af27776684"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.31509128688600785\n",
            "Epoch 2/10, Loss: 0.2881807416077316\n",
            "Epoch 3/10, Loss: 0.2756866514330419\n",
            "Epoch 4/10, Loss: 0.26829316512808715\n",
            "Epoch 5/10, Loss: 0.2626894886523339\n",
            "Epoch 6/10, Loss: 0.2588758379041756\n",
            "Epoch 7/10, Loss: 0.2546636423683367\n",
            "Epoch 8/10, Loss: 0.25260057040040373\n",
            "Epoch 9/10, Loss: 0.24989720895644268\n",
            "Epoch 10/10, Loss: 0.24812047050169575\n",
            "Test Accuracy: 92.01%\n"
          ]
        }
      ]
    }
  ]
}